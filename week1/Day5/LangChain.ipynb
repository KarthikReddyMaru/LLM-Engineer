{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from IPython.display import display, Markdown, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model = 'gpt-oss:latest')\n",
    "\n",
    "messages = HumanMessage(content = '50 words about Kratos')\n",
    "\n",
    "stream = model.stream(input = [messages])\n",
    "display_handle = display(Markdown(\"\"), display_id = True)\n",
    "\n",
    "response = ''\n",
    "for chunk in stream:\n",
    "    response += chunk.content or ''\n",
    "    update_display(Markdown(response), display_id = display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, convert_to_messages\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f60f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"vector_db\"\n",
    "EMBEDDING_MODEL = \"all-minilm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3767fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_files = glob.glob(pathname = 'knowledge-base/**/*.md', recursive = True)\n",
    "\n",
    "knowledge_base = ''\n",
    "\n",
    "for file in knowledge_base_files:\n",
    "    with open(file, 'r') as data:\n",
    "        knowledge_base += data.read()\n",
    "        knowledge_base += '\\n\\n\\n'\n",
    "\n",
    "print(f\"Total files: {len(knowledge_base_files)}, Chars: {len(knowledge_base)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_folders = glob.glob(pathname = 'knowledge-base/*')\n",
    "\n",
    "documents = []\n",
    "\n",
    "# for folder in knowledge_base_folders:\n",
    "for folder in knowledge_base_folders:\n",
    "    print(folder)\n",
    "    files = DirectoryLoader(\n",
    "        path = folder, \n",
    "        glob = \"**/*.md\", \n",
    "        recursive = True, \n",
    "        loader_cls = TextLoader,\n",
    "        loader_kwargs = {\"encoding\":'utf-8'}).lazy_load()\n",
    "\n",
    "    for file in files:\n",
    "        file.metadata['doc_type'] = os.path.basename(folder)\n",
    "        documents.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c81421",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 512, chunk_overlap = 64)\n",
    "chunks = text_splitter.split_documents(documents = documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model = EMBEDDING_MODEL)\n",
    "\n",
    "Chroma(persist_directory = DB_NAME, embedding_function = embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = embeddings,\n",
    "    persist_directory = DB_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectordb._collection.count()\n",
    "dimensions = vectordb.get(limit = 1, include = ['embeddings']).get('embeddings', []).shape\n",
    "\n",
    "print(f\"Vectors: {vectors} with dimensions: {dimensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc249b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a knowledgeable, friendly assistant representing the company Insurellm.\n",
    "You are chatting with a user about Insurellm.\n",
    "If relevant, use the given context to answer any question.\n",
    "If you don't know the answer, say so.\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "llm = ChatOllama(model = 'gpt-oss:latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = convert_to_messages(history)\n",
    "    context = retriever.invoke(message)\n",
    "    system = SystemMessage(content = SYSTEM_PROMPT_TEMPLATE.format(context = context))\n",
    "    user = HumanMessage(content = message)\n",
    "    stream = llm.stream(input = [system, user])\n",
    "\n",
    "    response = ''\n",
    "    for chunk in stream:\n",
    "        response += chunk.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fee14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio import ChatInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatInterface(fn = chat, type = 'messages').launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
